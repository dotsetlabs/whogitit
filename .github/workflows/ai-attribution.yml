name: AI Attribution Summary

on:
  pull_request:
    types: [opened, synchronize, reopened]

permissions:
  contents: read
  pull-requests: write
  checks: write

jobs:
  analyze:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history for git notes
          ref: ${{ github.event.pull_request.head.sha }}

      - name: Fetch git notes
        run: |
          git fetch origin refs/notes/whogitit:refs/notes/whogitit || echo "No whogitit notes found"
        continue-on-error: true

      - name: Setup Rust
        uses: dtolnay/rust-toolchain@stable

      - name: Cache cargo
        uses: actions/cache@v4
        with:
          path: |
            ~/.cargo/bin/
            ~/.cargo/registry/index/
            ~/.cargo/registry/cache/
            ~/.cargo/git/db/
            target/
          key: ${{ runner.os }}-cargo-${{ hashFiles('**/Cargo.lock') }}
          restore-keys: |
            ${{ runner.os }}-cargo-

      - name: Build whogitit
        run: cargo build --release

      - name: Analyze PR commits
        id: analyze
        env:
          BASE_SHA: ${{ github.event.pull_request.base.sha }}
          HEAD_SHA: ${{ github.event.pull_request.head.sha }}
        run: |
          # Create analysis script
          cat > /tmp/analyze.sh << 'SCRIPT'
          #!/bin/bash
          set -e

          BASE_SHA="$1"
          HEAD_SHA="$2"
          WHOGITIT="./target/release/whogitit"

          # Get list of commits in PR
          COMMITS=$(git rev-list --reverse "$BASE_SHA".."$HEAD_SHA")

          if [ -z "$COMMITS" ]; then
            echo "No commits to analyze"
            echo "has_data=false" >> "$GITHUB_OUTPUT"
            exit 0
          fi

          # Initialize counters
          TOTAL_AI=0
          TOTAL_AI_MODIFIED=0
          TOTAL_HUMAN=0
          COMMITS_WITH_AI=0
          COMMIT_COUNT=0

          # Collect per-commit data
          COMMIT_DETAILS=""
          # Collect per-file data
          declare -A FILE_AI
          declare -A FILE_AI_MOD
          declare -A FILE_HUMAN
          declare -A FILE_IS_NEW
          FILE_LIST=""
          # Track unique prompts (deduplicated across commits)
          declare -A SEEN_PROMPTS
          PROMPT_LIST=""
          PROMPT_COUNT=0

          for COMMIT in $COMMITS; do
            COMMIT_COUNT=$((COMMIT_COUNT + 1))
            SHORT=$(echo "$COMMIT" | cut -c1-7)

            # Try to get attribution for this commit
            if ATTR=$("$WHOGITIT" show "$COMMIT" --format json 2>/dev/null); then
              # Skip if no attribution (null output)
              if [ "$ATTR" = "null" ]; then
                continue
              fi
              # Parse JSON output
              AI=$(echo "$ATTR" | jq -r '[.files[].summary.ai_lines] | add // 0')
              AI_MOD=$(echo "$ATTR" | jq -r '[.files[].summary.ai_modified_lines] | add // 0')
              HUMAN=$(echo "$ATTR" | jq -r '[.files[].summary.human_lines] | add // 0')
              ORIGINAL=$(echo "$ATTR" | jq -r '[.files[].summary.original_lines] | add // 0')
              MODEL=$(echo "$ATTR" | jq -r '.session.model.id // "unknown"')
              FILES=$(echo "$ATTR" | jq -r '.files | length')

              if [ "$AI" != "0" ] || [ "$AI_MOD" != "0" ]; then
                COMMITS_WITH_AI=$((COMMITS_WITH_AI + 1))
                TOTAL_AI=$((TOTAL_AI + AI))
                TOTAL_AI_MODIFIED=$((TOTAL_AI_MODIFIED + AI_MOD))
                TOTAL_HUMAN=$((TOTAL_HUMAN + HUMAN))

                # Collect per-file statistics
                FILE_DATA=$(echo "$ATTR" | jq -r '.files[] | "\(.path)|\(.summary.ai_lines)|\(.summary.ai_modified_lines)|\(.summary.human_lines)|\(.summary.original_lines)"' 2>/dev/null || true)
                for FILE_LINE in $FILE_DATA; do
                  F_PATH=$(echo "$FILE_LINE" | cut -d'|' -f1)
                  F_AI=$(echo "$FILE_LINE" | cut -d'|' -f2)
                  F_AI_MOD=$(echo "$FILE_LINE" | cut -d'|' -f3)
                  F_HUMAN=$(echo "$FILE_LINE" | cut -d'|' -f4)
                  F_ORIG=$(echo "$FILE_LINE" | cut -d'|' -f5)

                  # Accumulate per-file stats
                  FILE_AI["$F_PATH"]=$((${FILE_AI["$F_PATH"]:-0} + F_AI))
                  FILE_AI_MOD["$F_PATH"]=$((${FILE_AI_MOD["$F_PATH"]:-0} + F_AI_MOD))
                  FILE_HUMAN["$F_PATH"]=$((${FILE_HUMAN["$F_PATH"]:-0} + F_HUMAN))

                  # Mark as new file if no original lines
                  if [ "$F_ORIG" = "0" ] && [ $((F_AI + F_AI_MOD + F_HUMAN)) -gt 0 ]; then
                    FILE_IS_NEW["$F_PATH"]=1
                  fi

                  # Track unique files
                  if [[ ! "$FILE_LIST" =~ "$F_PATH" ]]; then
                    FILE_LIST="${FILE_LIST}${F_PATH}|||"
                  fi
                done

                # Get commit message (first line)
                MSG=$(git log -1 --format=%s "$COMMIT" | head -c 50)

                COMMIT_DETAILS="${COMMIT_DETAILS}| \`${SHORT}\` | ${MSG} | ${AI} | ${AI_MOD} | ${HUMAN} | ${FILES} |
          "

                # Extract prompts from this commit (deduplicated)
                # Get files changed in this commit for better file association
                COMMIT_FILES=$(git diff-tree --no-commit-id --name-only -r "$COMMIT" 2>/dev/null | tr '\n' ', ' | sed 's/,$//')

                PROMPTS=$(echo "$ATTR" | jq -r '.prompts[]? | @base64' 2>/dev/null || true)
                for PROMPT_B64 in $PROMPTS; do
                  # Decode and extract prompt text (full text, up to 2000 chars)
                  PROMPT_TEXT=$(echo "$PROMPT_B64" | base64 -d | jq -r '.text // ""' 2>/dev/null | head -c 2000)

                  # Get affected files and make them relative/clean
                  RAW_FILES=$(echo "$PROMPT_B64" | base64 -d | jq -r '.affected_files[]?' 2>/dev/null || echo "")
                  PROMPT_FILES=""
                  for FILE in $RAW_FILES; do
                    # Make path relative to repo if it's inside the repo
                    if [[ "$FILE" == "$PWD"/* ]]; then
                      FILE="${FILE#$PWD/}"
                    elif [[ "$FILE" == /* ]]; then
                      # Absolute path outside repo - skip or just show basename
                      FILE=$(basename "$FILE")
                    fi
                    if [ -n "$PROMPT_FILES" ]; then
                      PROMPT_FILES="$PROMPT_FILES, $FILE"
                    else
                      PROMPT_FILES="$FILE"
                    fi
                  done

                  # If no files from prompt, use commit files
                  if [ -z "$PROMPT_FILES" ]; then
                    PROMPT_FILES="$COMMIT_FILES"
                  fi

                  # Skip empty or default prompts
                  if [ -z "$PROMPT_TEXT" ] || [ "$PROMPT_TEXT" = "AI-assisted code change" ]; then
                    continue
                  fi

                  # Remove surrounding quotes if present
                  PROMPT_TEXT=$(echo "$PROMPT_TEXT" | sed 's/^"//;s/"$//')

                  # Create a hash key for deduplication (first 100 chars)
                  PROMPT_KEY=$(echo "$PROMPT_TEXT" | head -c 100 | md5sum | cut -d' ' -f1)

                  if [ -z "${SEEN_PROMPTS[$PROMPT_KEY]:-}" ]; then
                    SEEN_PROMPTS[$PROMPT_KEY]=1
                    PROMPT_COUNT=$((PROMPT_COUNT + 1))

                    # Store full prompt for detailed view (escape for JSON)
                    FULL_PROMPT=$(echo "$PROMPT_TEXT" | jq -Rs '.' | sed 's/^"//;s/"$//')

                    # Create short preview (first 100 chars, single line)
                    PROMPT_PREVIEW=$(echo "$PROMPT_TEXT" | tr '\n' ' ' | head -c 100)
                    if [ ${#PROMPT_TEXT} -gt 100 ]; then
                      PROMPT_PREVIEW="${PROMPT_PREVIEW}..."
                    fi

                    # Escape special markdown characters
                    PROMPT_PREVIEW=$(echo "$PROMPT_PREVIEW" | sed 's/|/\\|/g')
                    FULL_PROMPT_ESCAPED=$(echo "$FULL_PROMPT" | sed 's/|/\\|/g')

                    # Build prompt entry - store as base64 to avoid YAML issues
                    PROMPT_ENTRY=$(echo -e "NUM:${PROMPT_COUNT}\nFILES:${PROMPT_FILES}\nPREVIEW:${PROMPT_PREVIEW}\nFULL:${PROMPT_TEXT}" | base64 -w0)
                    PROMPT_LIST="${PROMPT_LIST}${PROMPT_ENTRY}|||"
                  fi
                done
              fi
            fi
          done

          # Total additions = AI + AI_modified + Human
          TOTAL_ADDITIONS=$((TOTAL_AI + TOTAL_AI_MODIFIED + TOTAL_HUMAN))

          if [ "$COMMITS_WITH_AI" -eq 0 ]; then
            echo "has_data=false" >> "$GITHUB_OUTPUT"
            exit 0
          fi

          # AI percentage is of additions only
          if [ "$TOTAL_ADDITIONS" -gt 0 ]; then
            AI_PERCENT=$(echo "scale=1; ($TOTAL_AI + $TOTAL_AI_MODIFIED) * 100 / $TOTAL_ADDITIONS" | bc)
          else
            AI_PERCENT="0"
          fi

          # Count files
          FILE_COUNT=$(echo "$FILE_LIST" | tr '|||' '\n' | grep -v '^$' | wc -l | tr -d ' ')

          # Build per-file details
          FILE_DETAILS=""
          for F_PATH in $(echo "$FILE_LIST" | tr '|||' '\n' | grep -v '^$'); do
            F_AI=${FILE_AI["$F_PATH"]:-0}
            F_AI_MOD=${FILE_AI_MOD["$F_PATH"]:-0}
            F_HUMAN=${FILE_HUMAN["$F_PATH"]:-0}
            F_ADDITIONS=$((F_AI + F_AI_MOD + F_HUMAN))
            F_AI_TOTAL=$((F_AI + F_AI_MOD))

            if [ "$F_ADDITIONS" -gt 0 ]; then
              F_AI_PCT=$(echo "scale=0; $F_AI_TOTAL * 100 / $F_ADDITIONS" | bc)
            else
              F_AI_PCT=0
            fi

            F_STATUS="Modified"
            if [ "${FILE_IS_NEW["$F_PATH"]:-0}" = "1" ]; then
              F_STATUS="New"
            fi

            FILE_DETAILS="${FILE_DETAILS}| \`${F_PATH}\` | +${F_ADDITIONS} | ${F_AI_TOTAL} | ${F_HUMAN} | ${F_AI_PCT}% | ${F_STATUS} |
          "
          done

          # Build summary
          echo "has_data=true" >> "$GITHUB_OUTPUT"
          echo "total_ai=$TOTAL_AI" >> "$GITHUB_OUTPUT"
          echo "total_ai_modified=$TOTAL_AI_MODIFIED" >> "$GITHUB_OUTPUT"
          echo "total_human=$TOTAL_HUMAN" >> "$GITHUB_OUTPUT"
          echo "total_additions=$TOTAL_ADDITIONS" >> "$GITHUB_OUTPUT"
          echo "commits_with_ai=$COMMITS_WITH_AI" >> "$GITHUB_OUTPUT"
          echo "commit_count=$COMMIT_COUNT" >> "$GITHUB_OUTPUT"
          echo "ai_percent=$AI_PERCENT" >> "$GITHUB_OUTPUT"
          echo "file_count=$FILE_COUNT" >> "$GITHUB_OUTPUT"

          # Write commit details to file for multi-line output
          echo "$COMMIT_DETAILS" > /tmp/commit_details.txt

          # Write file details to file
          echo "$FILE_DETAILS" > /tmp/file_details.txt

          # Write prompts to file
          echo "$PROMPT_LIST" > /tmp/prompts.txt
          echo "prompt_count=$PROMPT_COUNT" >> "$GITHUB_OUTPUT"
          SCRIPT

          chmod +x /tmp/analyze.sh
          /tmp/analyze.sh "$BASE_SHA" "$HEAD_SHA"

      - name: Generate annotations
        if: steps.analyze.outputs.has_data == 'true'
        id: annotations
        env:
          BASE_SHA: ${{ github.event.pull_request.base.sha }}
          HEAD_SHA: ${{ github.event.pull_request.head.sha }}
        run: |
          # Generate annotations JSON using the new annotations command
          ./target/release/whogitit annotations \
            --base "$BASE_SHA" \
            --head "$HEAD_SHA" \
            --format github-checks \
            --max-annotations 50 > /tmp/annotations.json 2>/dev/null || echo '{"annotations":[],"summary":{}}' > /tmp/annotations.json

          # Check if we have annotations
          ANNOTATION_COUNT=$(jq '.annotations | length' /tmp/annotations.json 2>/dev/null || echo "0")
          echo "annotation_count=$ANNOTATION_COUNT" >> "$GITHUB_OUTPUT"

      - name: Create Check Run with Annotations
        if: steps.analyze.outputs.has_data == 'true' && steps.annotations.outputs.annotation_count != '0'
        uses: actions/github-script@v7
        env:
          HEAD_SHA: ${{ github.event.pull_request.head.sha }}
          AI_PERCENT: ${{ steps.analyze.outputs.ai_percent }}
          TOTAL_AI: ${{ steps.analyze.outputs.total_ai }}
          TOTAL_AI_MODIFIED: ${{ steps.analyze.outputs.total_ai_modified }}
          FILE_COUNT: ${{ steps.analyze.outputs.file_count }}
        with:
          script: |
            const fs = require('fs');

            // Read annotations from file
            let annotationsData;
            try {
              annotationsData = JSON.parse(fs.readFileSync('/tmp/annotations.json', 'utf8'));
            } catch (e) {
              console.log('Failed to read annotations:', e.message);
              return;
            }

            const annotations = annotationsData.annotations || [];
            if (annotations.length === 0) {
              console.log('No annotations to create');
              return;
            }

            const aiPercent = process.env.AI_PERCENT || '0';
            const totalAI = parseInt(process.env.TOTAL_AI) || 0;
            const totalAIMod = parseInt(process.env.TOTAL_AI_MODIFIED) || 0;
            const fileCount = parseInt(process.env.FILE_COUNT) || 0;
            const model = annotationsData.summary?.model || 'unknown';

            // Create check run
            const checkRun = await github.rest.checks.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              name: 'AI Attribution',
              head_sha: process.env.HEAD_SHA,
              status: 'completed',
              conclusion: 'neutral',
              output: {
                title: `${aiPercent}% AI-generated (${totalAI + totalAIMod} lines)`,
                summary: `This PR contains AI-generated code tracked by whogitit.\n\n` +
                  `- **AI-generated lines:** ${totalAI}\n` +
                  `- **AI-modified lines:** ${totalAIMod}\n` +
                  `- **Files with AI code:** ${fileCount}\n` +
                  `- **Model:** ${model}\n\n` +
                  `Click on individual annotations in the "Files changed" tab to see attribution details.`,
                annotations: annotations.slice(0, 50).map(a => ({
                  path: a.path,
                  start_line: a.start_line,
                  end_line: a.end_line,
                  annotation_level: a.annotation_level,
                  title: a.title,
                  message: a.message,
                  raw_details: a.raw_details || undefined
                }))
              }
            });

            console.log(`Created check run with ${annotations.length} annotations`);

            // If more than 50 annotations, update with additional batches
            // GitHub allows up to 50 annotations per API call
            for (let i = 50; i < annotations.length; i += 50) {
              const batch = annotations.slice(i, i + 50);
              await github.rest.checks.update({
                owner: context.repo.owner,
                repo: context.repo.repo,
                check_run_id: checkRun.data.id,
                output: {
                  title: `${aiPercent}% AI-generated (${totalAI + totalAIMod} lines)`,
                  summary: `This PR contains AI-generated code tracked by whogitit.\n\n` +
                    `- **AI-generated lines:** ${totalAI}\n` +
                    `- **AI-modified lines:** ${totalAIMod}\n` +
                    `- **Files with AI code:** ${fileCount}\n` +
                    `- **Model:** ${model}\n\n` +
                    `Click on individual annotations in the "Files changed" tab to see attribution details.`,
                  annotations: batch.map(a => ({
                    path: a.path,
                    start_line: a.start_line,
                    end_line: a.end_line,
                    annotation_level: a.annotation_level,
                    title: a.title,
                    message: a.message,
                    raw_details: a.raw_details || undefined
                  }))
                }
              });
              console.log(`Added batch of ${batch.length} annotations`);
            }

      - name: Post PR comment
        if: steps.analyze.outputs.has_data == 'true'
        uses: actions/github-script@v7
        env:
          TOTAL_AI: ${{ steps.analyze.outputs.total_ai }}
          TOTAL_AI_MODIFIED: ${{ steps.analyze.outputs.total_ai_modified }}
          TOTAL_HUMAN: ${{ steps.analyze.outputs.total_human }}
          TOTAL_ADDITIONS: ${{ steps.analyze.outputs.total_additions }}
          COMMITS_WITH_AI: ${{ steps.analyze.outputs.commits_with_ai }}
          COMMIT_COUNT: ${{ steps.analyze.outputs.commit_count }}
          AI_PERCENT: ${{ steps.analyze.outputs.ai_percent }}
          FILE_COUNT: ${{ steps.analyze.outputs.file_count }}
          PROMPT_COUNT: ${{ steps.analyze.outputs.prompt_count }}
        with:
          script: |
            const fs = require('fs');

            const totalAI = parseInt(process.env.TOTAL_AI) || 0;
            const totalAIMod = parseInt(process.env.TOTAL_AI_MODIFIED) || 0;
            const totalHuman = parseInt(process.env.TOTAL_HUMAN) || 0;
            const totalAdditions = parseInt(process.env.TOTAL_ADDITIONS) || 0;
            const commitsWithAI = parseInt(process.env.COMMITS_WITH_AI) || 0;
            const commitCount = parseInt(process.env.COMMIT_COUNT) || 0;
            const aiPercent = process.env.AI_PERCENT || '0';
            const fileCount = parseInt(process.env.FILE_COUNT) || 0;
            const promptCount = parseInt(process.env.PROMPT_COUNT) || 0;

            // Read commit details
            let commitDetails = '';
            try {
              commitDetails = fs.readFileSync('/tmp/commit_details.txt', 'utf8').trim();
            } catch (e) {
              console.log('No commit details file found');
            }

            // Read file details
            let fileDetails = '';
            try {
              fileDetails = fs.readFileSync('/tmp/file_details.txt', 'utf8').trim();
            } catch (e) {
              console.log('No file details file found');
            }

            // Read and parse prompts (base64 encoded, separated by |||)
            let parsedPrompts = [];
            try {
              const rawPrompts = fs.readFileSync('/tmp/prompts.txt', 'utf8').trim();
              const promptBlocks = rawPrompts.split('|||').filter(b => b.trim());
              for (const b64 of promptBlocks) {
                try {
                  const decoded = Buffer.from(b64.trim(), 'base64').toString('utf8');
                  const lines = decoded.split('\n');
                  const prompt = {};
                  let fullLines = [];
                  let inFull = false;

                  for (const line of lines) {
                    if (line.startsWith('NUM:')) {
                      prompt.num = line.replace('NUM:', '').trim();
                    } else if (line.startsWith('FILES:')) {
                      prompt.files = line.replace('FILES:', '').trim();
                    } else if (line.startsWith('PREVIEW:')) {
                      prompt.preview = line.replace('PREVIEW:', '').trim();
                    } else if (line.startsWith('FULL:')) {
                      inFull = true;
                      fullLines.push(line.replace('FULL:', ''));
                    } else if (inFull) {
                      fullLines.push(line);
                    }
                  }
                  prompt.full = fullLines.join('\n').trim();
                  if (prompt.num) parsedPrompts.push(prompt);
                } catch (decodeErr) {
                  console.log('Failed to decode prompt:', decodeErr.message);
                }
              }
            } catch (e) {
              console.log('No prompts file found or parse error:', e.message);
            }

            // Determine emoji based on AI percentage
            let emoji = 'ðŸ¤–';
            const pct = parseFloat(aiPercent);
            if (pct >= 80) emoji = 'ðŸ¤–ðŸ¤–ðŸ¤–';
            else if (pct >= 50) emoji = 'ðŸ¤–ðŸ¤–';
            else if (pct >= 20) emoji = 'ðŸ¤–';
            else emoji = 'ðŸ‘¤';

            // Calculate percentages based on additions only
            const aiPct = totalAdditions > 0 ? ((totalAI / totalAdditions) * 100).toFixed(1) : '0.0';
            const aiModPct = totalAdditions > 0 ? ((totalAIMod / totalAdditions) * 100).toFixed(1) : '0.0';
            const humanPct = totalAdditions > 0 ? ((totalHuman / totalAdditions) * 100).toFixed(1) : '0.0';

            let body = `## ${emoji} AI Attribution Summary

            This PR adds **+${totalAdditions}** lines with AI attribution across **${fileCount}** files.

            ### Additions Breakdown

            | Metric | Lines | % of Additions |
            |--------|------:|--------------:|
            | ðŸŸ¢ AI-generated | +${totalAI} | ${aiPct}% |
            | ðŸŸ¡ AI-modified by human | +${totalAIMod} | ${aiModPct}% |
            | ðŸ”µ Human-written | +${totalHuman} | ${humanPct}% |
            | **Total additions** | **+${totalAdditions}** | **100%** |

            **AI involvement: ${aiPercent}%** of additions are AI-generated

            `;

            if (fileDetails) {
              body += `### Files Changed

            | File | +Added | AI | Human | AI % | Status |
            |------|-------:|---:|------:|-----:|--------|
            ${fileDetails}
            `;
            }

            if (commitDetails) {
              body += `### Commits with AI Attribution

            | Commit | Message | AI | Modified | Human | Files |
            |--------|---------|---:|--------:|------:|------:|
            ${commitDetails}
            `;
            }

            if (parsedPrompts.length > 0) {
              body += '### Prompts Used (' + parsedPrompts.length + ')\n\n';
              for (const p of parsedPrompts) {
                body += '**Prompt ' + p.num + '** (' + p.files + ')\n';
                body += '<details>\n';
                body += '<summary>' + p.preview + '</summary>\n\n';
                body += '```\n';
                body += p.full + '\n';
                body += '```\n';
                body += '</details>\n\n';
              }
            }

            body += `
            ---
            <sub>Generated by [whogitit](https://github.com/dotsetlabs/whogitit) â€¢ [View detailed attribution](command:whogitit show HEAD)</sub>
            `;

            // Find existing comment
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });

            const botComment = comments.find(c =>
              c.user.type === 'Bot' &&
              c.body.includes('AI Attribution Summary')
            );

            if (botComment) {
              // Update existing comment
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: body
              });
              console.log('Updated existing comment');
            } else {
              // Create new comment
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: body
              });
              console.log('Created new comment');
            }

      - name: No AI attribution found
        if: steps.analyze.outputs.has_data != 'true'
        run: |
          echo "No AI attribution data found in this PR's commits."
          echo "This is normal if the commits were not made with whogitit tracking enabled."
